# íŒŒì¼ ìœ„ì¹˜: extractors/soup_extractor.py

import logging
from bs4 import BeautifulSoup, NavigableString
from extractors.base_extractor import BaseExtractor
import trafilatura
from readability import Document
from urllib.parse import urljoin

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format="[%(asctime)s] [%(levelname)s] [soup_extractor.py] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)

class SoupExtractor(BaseExtractor):
    """
    trafilatura â†’ readability fallback ë°©ì‹ì˜ ë³¸ë¬¸ ì¶”ì¶œê¸°
    """

    def __init__(self, html: str, base_url: str = ""):
        super().__init__(html)
        self.html = html
        self.soup = BeautifulSoup(html, "lxml")
        self.base_url = base_url
        self.trafilatura_result = trafilatura.extract(
            html,
            include_comments=False,
            include_tables=False,
            include_formatting=True
        )
        logging.info("SoupExtractor ì´ˆê¸°í™” ì™„ë£Œ")

    def get_title(self) -> str:
        if self.soup.title:
            title = self.soup.title.get_text(strip=True)
            logging.info(f"ì œëª© ì¶”ì¶œ ì™„ë£Œ: {title}")
            return title

        try:
            doc = Document(self.html)
            title = doc.title()
            logging.info(f"[Fallback] ì œëª© ì¶”ì¶œ ì™„ë£Œ (readability): {title}")
            return title
        except Exception as e:
            logging.warning(f"ì œëª© ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return ""

    def get_text(self) -> str:
        if self.trafilatura_result and len(self.trafilatura_result) > 100:
            logging.info(f"ë³¸ë¬¸ ì¶”ì¶œ ì„±ê³µ (trafilatura, ê¸¸ì´: {len(self.trafilatura_result)}ì)")
            return self.trafilatura_result

        try:
            doc = Document(self.html)
            content_html = doc.summary()
            content_soup = BeautifulSoup(content_html, "lxml")
            text = content_soup.get_text(separator="\n", strip=True)
            logging.warning("ë³¸ë¬¸ ì¶”ì¶œ fallback ì‚¬ìš© (readability)")
            return text
        except Exception as e:
            logging.error(f"ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return ""

    def get_text_with_images(self) -> str:
        try:
            doc = Document(self.html)
            content_html = doc.summary()
            content_soup = BeautifulSoup(content_html, "lxml")

            output_parts = []

            for tag in content_soup.find_all(["p", "img", "h1", "h2", "h3", "ul", "ol", "li", "blockquote"]):
                if tag.name == "p":
                    para = tag.get_text(" ", strip=True)
                    imgs = tag.find_all("img")
                    for img in imgs:
                        src = img.get("src")
                        if src:
                            full_url = urljoin(self.base_url, src)
                            para += f"\n\n![image]({full_url})"
                    if para:
                        output_parts.append(para)

                elif tag.name == "img":
                    src = tag.get("src")
                    if src:
                        full_url = urljoin(self.base_url, src)
                        output_parts.append(f"![image]({full_url})")

                elif tag.name in ["h1", "h2", "h3"]:
                    level = int(tag.name[1])
                    text = tag.get_text(" ", strip=True)
                    output_parts.append(f"{'#' * level} {text}")

                elif tag.name == "li":
                    output_parts.append(f"- {tag.get_text(' ', strip=True)}")

                elif tag.name == "blockquote":
                    block = tag.get_text(" ", strip=True)
                    output_parts.append(f"> {block}")

            result = "\n\n".join(output_parts)
            logging.info("ë³¸ë¬¸+ì´ë¯¸ì§€ ì¶”ì¶œ ì„±ê³µ (readability ê¸°ë°˜)")
            return result

        except Exception as e:
            logging.error(f"ë³¸ë¬¸+ì´ë¯¸ì§€ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return self.get_text()

    def get_image(self) -> str:
        og_image = self.soup.find("meta", property="og:image")
        if og_image and og_image.get("content"):
            url = urljoin(self.base_url, og_image["content"])
            logging.info(f"ëŒ€í‘œ ì´ë¯¸ì§€ ì¶”ì¶œ ì„±ê³µ: og:image â†’ {url}")
            return url

        first_img = self.soup.find("img")
        if first_img and first_img.get("src"):
            url = urljoin(self.base_url, first_img["src"])
            logging.info(f"ëŒ€í‘œ ì´ë¯¸ì§€ ì¶”ì¶œ ì„±ê³µ: <img> íƒœê·¸ â†’ {url}")
            return url

        all_images = self.get_images()
        if all_images:
            logging.info(f"ëŒ€í‘œ ì´ë¯¸ì§€ fallback ì‚¬ìš© â†’ {all_images[0]}")
            return all_images[0]

        logging.warning("ëŒ€í‘œ ì´ë¯¸ì§€ ì—†ìŒ")
        return ""

    def get_images(self) -> list:
        image_urls = []
        img_tags = self.soup.find_all("img")
        logging.info(f"ì´ <img> íƒœê·¸ ìˆ˜: {len(img_tags)}")

        for img in img_tags:
            src = img.get("src")
            if src:
                full_url = urljoin(self.base_url, src)
                image_urls.append(full_url)
                logging.info(f"ğŸ“¸ ë³¸ë¬¸ ì´ë¯¸ì§€ í¬ì°©: {full_url}")

        if image_urls:
            logging.info(f"ë³¸ë¬¸ ì´ë¯¸ì§€ ì´ {len(image_urls)}ê°œ ì¶”ì¶œ ì™„ë£Œ")
        else:
            logging.warning("âš ï¸ ë³¸ë¬¸ì—ì„œ ì´ë¯¸ì§€ê°€ í¬ì°©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        return image_urls