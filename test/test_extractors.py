# test/test_extractors.py

import os
import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import logging
from utils.fetcher import fetch_html
from utils.translator import translate_to_korean
from utils.keywords import extract_keywords
from extractors.soup_extractor import SoupExtractor
from extractors.readability import ReadabilityExtractor

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format="[%(asctime)s] [%(levelname)s] [test_extractors.py] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)

def test_extractors(url: str):
    logging.info(f"ğŸ” í…ŒìŠ¤íŠ¸ ì‹œì‘: {url}")

    try:
        html = fetch_html(url)
        logging.info("âœ… HTML ê°€ì ¸ì˜¤ê¸° ì™„ë£Œ")
    except Exception as e:
        logging.error(f"âŒ HTML ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return

    # SoupExtractor í…ŒìŠ¤íŠ¸
    try:
        soup_extractor = SoupExtractor(html)
        soup_title = soup_extractor.get_title()
        soup_text = soup_extractor.get_text()
        soup_image = soup_extractor.get_image()
        soup_translated = translate_to_korean(soup_text)
        soup_keywords = extract_keywords(soup_text)
        logging.info("âœ… SoupExtractor ì‹¤í–‰ ì™„ë£Œ")
    except Exception as e:
        logging.error(f"âŒ SoupExtractor ì˜¤ë¥˜: {e}")
        soup_title = soup_text = soup_image = soup_translated = "ERROR"
        soup_keywords = []

    # ReadabilityExtractor í…ŒìŠ¤íŠ¸
    try:
        read_extractor = ReadabilityExtractor(html)
        read_title = read_extractor.get_title()
        read_text = read_extractor.get_text()
        read_image = read_extractor.get_image()
        read_translated = translate_to_korean(read_text)
        read_keywords = extract_keywords(read_text)
        logging.info("âœ… ReadabilityExtractor ì‹¤í–‰ ì™„ë£Œ")
    except Exception as e:
        logging.error(f"âŒ ReadabilityExtractor ì˜¤ë¥˜: {e}")
        read_title = read_text = read_image = read_translated = "ERROR"
        read_keywords = []

    # ê²°ê³¼ ë¹„êµ ì¶œë ¥
    print("\n========== ê²°ê³¼ ë¹„êµ ==========")
    print(f"[URL] {url}\n")

    print("[SoupExtractor]")
    print(f"ì œëª©: {soup_title}")
    print(f"ì´ë¯¸ì§€: {soup_image}")
    print(f"ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸°:\n{soup_text[:300]}...\n")
    print(f"ë²ˆì—­ë¬¸ ë¯¸ë¦¬ë³´ê¸°:\n{soup_translated[:300]}...\n")
    print(f"í‚¤ì›Œë“œ ë¯¸ë¦¬ë³´ê¸°: {soup_keywords}\n")

    print("[ReadabilityExtractor]")
    print(f"ì œëª©: {read_title}")
    print(f"ì´ë¯¸ì§€: {read_image}")
    print(f"ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸°:\n{read_text[:300]}...")
    print(f"ë²ˆì—­ë¬¸ ë¯¸ë¦¬ë³´ê¸°:\n{read_translated[:300]}...")
    print(f"í‚¤ì›Œë“œ ë¯¸ë¦¬ë³´ê¸°: {read_keywords}")
    print("================================\n")


if __name__ == "__main__":
    urls = [
        "https://example.com",
        "https://www.bbc.com/sport/articles/cglxwrj2501o",
        "https://blog.naver.com/PostView.naver?blogId=ronalee&logNo=223856131195&redirect=Dlog&widgetTypeCall=true&from=section&topReferer=https%3A%2F%2Fsection.blog.naver.com%2FBlogHome.naver%3FdirectoryNo%3D0%26currentPage%3D1%26groupId%3D0&trackingCode=blog_sectionhome_pc&directAccess=false"
    ]

    for url in urls:
        test_extractors(url)